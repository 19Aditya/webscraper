# webscraper
Used BeautifulSoup w requests library (for parsing through HTML content), Selenium along with webdriver(for getting dynamic generated content) to scrape website, facilitating data aggregation and data analysis.
this repo contains following files : 
- basic.py : Used BeautifulSoup for navigating through html provided looking for targeted. Could've got the html from HTTP req of a url via Requests Library.
- onTestSite : used Selenium to scrape through a scraping test site. Collecting data on all the quotes listed on different pages
-dummyEcommerce : scraped through a dummy e-commerce website to track price of a product